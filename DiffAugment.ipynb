{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "\n",
    "from utils.preprocessing import (\n",
    "    load_dataset,\n",
    "    get_gan_dataset, get_photo_dataset,\n",
    ")\n",
    "\n",
    "from utils.gan import generator, discriminator\n",
    "\n",
    "from utils.diffaugmentation import data_augment_flip, CycleGan\n",
    "\n",
    "from utils.cyclegan import (\n",
    "    generator_loss, discriminator_loss,\n",
    "    calc_cycle_loss, identity_loss\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Device:', tpu.master())\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "except:\n",
    "    strategy = tf.distribute.get_strategy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAINTER = \"monet\"\n",
    "# PAINTER = \"vangogh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of files in the monet and photo directories\n",
    "data_dir = ('data/')\n",
    "\n",
    "if PAINTER == \"monet\":\n",
    "    PAINTER_FILES = tf.io.gfile.glob(str(data_dir + 'monet_tfrec/*.tfrec'))\n",
    "if PAINTER == \"vangogh\":\n",
    "    PAINTER_FILES = tf.io.gfile.glob(str(data_dir + 'vangogh_tfrec/*.tfrecord'))\n",
    "\n",
    "PHOTO_FILES = tf.io.gfile.glob(str(data_dir + 'photo_tfrec/*.tfrec'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_data_items(filenames):\n",
    "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
    "    return np.sum(n)\n",
    "\n",
    "n_paint_samples = count_data_items(PAINTER_FILES)\n",
    "n_photo_samples = count_data_items(PHOTO_FILES)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE =  128\n",
    "EPOCHS_NUM = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = get_gan_dataset(PAINTER_FILES, PHOTO_FILES, augment=data_augment_flip, repeat=True, shuffle=False, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    paint_generator = generator()\n",
    "    photo_generator = generator()\n",
    "\n",
    "    paint_discriminator = discriminator()\n",
    "    photo_discriminator = discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    paint_generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "    photo_generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "\n",
    "    paint_discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "    photo_discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    cycle_gan_model = CycleGan(\n",
    "        paint_generator, photo_generator, paint_discriminator, photo_discriminator\n",
    "    )\n",
    "\n",
    "    cycle_gan_model.compile(\n",
    "        paint_gen_optimizer = paint_generator_optimizer,\n",
    "        photo_gen_optimizer = photo_generator_optimizer,\n",
    "        paint_disc_optimizer = paint_discriminator_optimizer,\n",
    "        photo_disc_optimizer = photo_discriminator_optimizer,\n",
    "        gen_loss_fn = generator_loss,\n",
    "        disc_loss_fn = discriminator_loss,\n",
    "        cycle_loss_fn = calc_cycle_loss,\n",
    "        identity_loss_fn = identity_loss\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle_gan_model.fit(\n",
    "    full_dataset,\n",
    "    epochs=EPOCHS_NUM,\n",
    "    steps_per_epoch=(max(n_paint_samples, n_photo_samples)//4),\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = 'images/cycleGAN/'\n",
    "paint_generator.save(SAVE_PATH + f'G_{PAINTER}.h5')\n",
    "photo_generator.save(SAVE_PATH + 'G_photo.h5')\n",
    "paint_discriminator.save(SAVE_PATH + f'D_{PAINTER}.h5')\n",
    "photo_discriminator.save(SAVE_PATH + 'D_photo.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the output images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "! mkdir output\n",
    "! mkdir output/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "for img in photos:\n",
    "    prediction = paint_discriminator(img, training=False)[0].numpy()\n",
    "    prediction = (prediction * 127.5 + 127.5).astype(np.uint8)\n",
    "    im = PIL.Image.fromarray(prediction)\n",
    "    im.save(\"output/images\" + str(i) + \".jpg\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.make_archive(\"output/output_diffaugment\", 'zip', \"output/images\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tulip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fe1432100fa846dd20953a7d0c263945e5c9df579f052187ee666d4bb0f5c425"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
