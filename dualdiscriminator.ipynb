{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from utils.preprocessing import load_dataset\n",
    "from utils.gan import generator\n",
    "\n",
    "from utils.preprocessing import get_gan_dataset\n",
    "\n",
    "from utils.diffaugmentation import data_augment_flip, aug_fn\n",
    "\n",
    "from utils.dualdiscriminator import (\n",
    "    discriminator_paint, discriminator_photo, d_head,\n",
    "    CycleGan,\n",
    "    generator_loss1, generator_loss2,\n",
    "    discriminator_loss1, discriminator_loss2,\n",
    "    calc_cycle_loss, identity_loss\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Device:', tpu.master())\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "except:\n",
    "    strategy = tf.distribute.get_strategy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAINTER = \"monet\"\n",
    "# PAINTER = \"vangogh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of files in the paint and photo directories\n",
    "data_dir = ('data/')\n",
    "\n",
    "if PAINTER == \"monet\":\n",
    "    PAINTER_FILES = tf.io.gfile.glob(str(data_dir + 'monet_tfrec/*.tfrec'))\n",
    "if PAINTER == \"vangogh\":\n",
    "    PAINTER_FILES = tf.io.gfile.glob(str(data_dir + 'vangogh_tfrec/*.tfrecord'))\n",
    "\n",
    "PHOTO_FILES = tf.io.gfile.glob(str(data_dir + 'photo_tfrec/*.tfrec'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paint_ds = load_dataset(PAINTER_FILES).batch(1)\n",
    "photo_ds = load_dataset(PHOTO_FILES).batch(1)\n",
    "\n",
    "\n",
    "fast_photo_ds = load_dataset(PHOTO_FILES).batch(32 * strategy.num_replicas_in_sync).prefetch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32 \n",
    "final_dataset = get_gan_dataset(PAINTER_FILES, PHOTO_FILES, augment=data_augment_flip, repeat=True, shuffle=True, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating and training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    paint_generator = generator()\n",
    "    photo_generator = generator()\n",
    "\n",
    "    paint_discriminator = discriminator_paint()\n",
    "    photo_discriminator = discriminator_photo()\n",
    "\n",
    "    d_head_bce = d_head()\n",
    "    d_head_hinge_loss = d_head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('checkpoints', exist_ok=True)\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor = 'total_loss',patience=10,restore_best_weights=True, mode='min'),\n",
    "    tf.keras.callbacks.TerminateOnNaN(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    paint_generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "    photo_generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "\n",
    "    paint_discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "    photo_discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    cycle_gan_model = CycleGan(\n",
    "        paint_generator, photo_generator,\n",
    "        paint_discriminator, photo_discriminator,\n",
    "        d_head_bce, d_head_hinge_loss,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    cycle_gan_model.compile(\n",
    "        paint_gen_optimizer = paint_generator_optimizer,\n",
    "        photo_gen_optimizer = photo_generator_optimizer,\n",
    "        paint_disc_optimizer = paint_discriminator_optimizer,\n",
    "        photo_disc_optimizer = photo_discriminator_optimizer,\n",
    "        gen_loss_fn1 = generator_loss1,\n",
    "        gen_loss_fn2 = generator_loss2,\n",
    "        disc_loss_fn1 = discriminator_loss1,\n",
    "        disc_loss_fn2 = discriminator_loss2,\n",
    "        cycle_loss_fn = calc_cycle_loss,\n",
    "        identity_loss_fn = identity_loss,\n",
    "        aug_fn = aug_fn,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle_gan_model.fit(final_dataset, steps_per_epoch=1407, epochs=23, callbacks=[callbacks])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualising the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_iter = iter(photo_ds)\n",
    "for n_sample in range(8):\n",
    "        example_sample = next(ds_iter)\n",
    "        generated_sample = paint_generator(example_sample)\n",
    "        \n",
    "        f = plt.figure(figsize=(32, 32))\n",
    "        \n",
    "        plt.subplot(121)\n",
    "        plt.title('Input image')\n",
    "        plt.imshow(example_sample[0] * 0.5 + 0.5)\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(122)\n",
    "        plt.title('Generated image')\n",
    "        plt.imshow(generated_sample[0] * 0.5 + 0.5)\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_iter = iter(paint_ds)\n",
    "for n_sample in range(10):\n",
    "\n",
    "        example_sample = next(ds_iter)\n",
    "        generated_sample = photo_generator(example_sample)\n",
    "        \n",
    "        f = plt.figure(figsize=(24, 24))\n",
    "        \n",
    "        plt.subplot(121)\n",
    "        plt.title('Input image')\n",
    "        plt.imshow(example_sample[0] * 0.5 + 0.5)\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(122)\n",
    "        plt.title('Generated image')\n",
    "        plt.imshow(generated_sample[0] * 0.5 + 0.5)\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "! mkdir ../images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "i = 1\n",
    "for img in fast_photo_ds:\n",
    "    prediction = monet_generator(img, training=False).numpy()\n",
    "    prediction = (prediction * 127.5 + 127.5).astype(np.uint8)\n",
    "    for pred in prediction:\n",
    "        im = PIL.Image.fromarray(pred)\n",
    "        im.save(\"output/images/\" + str(i) + \".jpg\")\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.make_archive(\"output/output_cyclegan\", 'zip', \"output/images\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = 'images/dualD/'\n",
    "paint_generator.save(SAVE_PATH + f'G_{PAINTER}.h5')\n",
    "photo_generator.save(SAVE_PATH + 'G_photo.h5')\n",
    "paint_discriminator.save(SAVE_PATH + f'D_{PAINTER}.h5')\n",
    "photo_discriminator.save(SAVE_PATH + 'D_photo.h5')\n",
    "d_head_bce.save(SAVE_PATH + 'D_head_bce.h5')\n",
    "d_head_hinge_loss.save(SAVE_PATH + 'D_head_hinge_loss.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tulip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fe1432100fa846dd20953a7d0c263945e5c9df579f052187ee666d4bb0f5c425"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
