{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from utils.preprocessing import load_dataset\n",
    "from utils.gan import generator\n",
    "\n",
    "from utils.preprocessing import get_gan_dataset\n",
    "\n",
    "from utils.diffaugmentation import data_augment_flip, aug_fn\n",
    "\n",
    "from utils.dualdiscriminator import (\n",
    "    discriminator_paint, discriminator_photo, d_head,\n",
    "    CycleGan,\n",
    "    generator_loss1, generator_loss2,\n",
    "    discriminator_loss1, discriminator_loss2,\n",
    "    calc_cycle_loss, identity_loss\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Device:', tpu.master())\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "except:\n",
    "    strategy = tf.distribute.get_strategy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAINTER = \"monet\"\n",
    "# PAINTER = \"vangogh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of files in the paint and photo directories\n",
    "data_dir = ('data/')\n",
    "\n",
    "if PAINTER == \"monet\":\n",
    "    PAINTER_FILES = tf.io.gfile.glob(str(data_dir + 'monet_tfrec/*.tfrec'))\n",
    "if PAINTER == \"vangogh\":\n",
    "    PAINTER_FILES = tf.io.gfile.glob(str(data_dir + 'vangogh_tfrec/*.tfrecord'))\n",
    "\n",
    "PHOTO_FILES = tf.io.gfile.glob(str(data_dir + 'photo_tfrec/*.tfrec'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-05 12:26:03.714063: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-02-05 12:26:03.714187: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "paint_ds = load_dataset(PAINTER_FILES).batch(1)\n",
    "photo_ds = load_dataset(PHOTO_FILES).batch(1)\n",
    "\n",
    "\n",
    "fast_photo_ds = load_dataset(PHOTO_FILES).batch(32 * strategy.num_replicas_in_sync).prefetch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32 \n",
    "final_dataset = get_gan_dataset(PAINTER_FILES, PHOTO_FILES, augment=data_augment_flip, repeat=True, shuffle=True, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating and training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    paint_generator = generator()\n",
    "    photo_generator = generator()\n",
    "\n",
    "    paint_discriminator = discriminator_paint()\n",
    "    photo_discriminator = discriminator_photo()\n",
    "\n",
    "    d_head_bce = d_head()\n",
    "    d_head_hinge_loss = d_head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('checkpoints', exist_ok=True)\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor = 'total_loss',patience=10,restore_best_weights=True, mode='min'),\n",
    "    tf.keras.callbacks.TerminateOnNaN(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    paint_generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "    photo_generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "\n",
    "    paint_discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "    photo_discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    cycle_gan_model = CycleGan(\n",
    "        paint_generator, photo_generator,\n",
    "        paint_discriminator, photo_discriminator,\n",
    "        d_head_bce, d_head_hinge_loss,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    cycle_gan_model.compile(\n",
    "        paint_gen_optimizer = paint_generator_optimizer,\n",
    "        photo_gen_optimizer = photo_generator_optimizer,\n",
    "        paint_disc_optimizer = paint_discriminator_optimizer,\n",
    "        photo_disc_optimizer = photo_discriminator_optimizer,\n",
    "        gen_loss_fn1 = generator_loss1,\n",
    "        gen_loss_fn2 = generator_loss2,\n",
    "        disc_loss_fn1 = discriminator_loss1,\n",
    "        disc_loss_fn2 = discriminator_loss2,\n",
    "        cycle_loss_fn = calc_cycle_loss,\n",
    "        identity_loss_fn = identity_loss,\n",
    "        aug_fn = aug_fn,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-05 12:26:05.876406: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/laurendurivault/Documents/GitHub/laurendudu/gans-and-monet/tulip/lib/python3.8/site-packages/keras/engine/training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/laurendurivault/Documents/GitHub/laurendudu/gans-and-monet/tulip/lib/python3.8/site-packages/keras/engine/training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/laurendurivault/Documents/GitHub/laurendudu/gans-and-monet/tulip/lib/python3.8/site-packages/keras/engine/training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/laurendurivault/Documents/GitHub/laurendudu/gans-and-monet/utils/dualdiscriminator.py\", line 149, in train_step\n        disc_fake_paint1 = self.dhead1(\n    File \"/Users/laurendurivault/Documents/GitHub/laurendudu/gans-and-monet/tulip/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/laurendurivault/Documents/GitHub/laurendudu/gans-and-monet/tulip/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model_4\" is incompatible with the layer: expected shape=(None, 30, 30, 512), found shape=(32, 33, 33, 512)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cycle_gan_model\u001b[39m.\u001b[39;49mfit(final_dataset, steps_per_epoch\u001b[39m=\u001b[39;49m\u001b[39m1407\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m23\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49m[callbacks])\n",
      "File \u001b[0;32m~/Documents/GitHub/laurendudu/gans-and-monet/tulip/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/jn/255yhly14195r8858jc1_c6r0000gn/T/__autograph_generated_filesi55q8ib.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/laurendudu/gans-and-monet/utils/dualdiscriminator.py:149\u001b[0m, in \u001b[0;36mCycleGan.train_step\u001b[0;34m(self, batch_data)\u001b[0m\n\u001b[1;32m    146\u001b[0m aug_fake_paint \u001b[39m=\u001b[39m aug_paint[batch_size:]\n\u001b[1;32m    148\u001b[0m \u001b[39m# two-objective discriminator\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m disc_fake_paint1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdhead1(\n\u001b[1;32m    150\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpaint_disc(aug_fake_paint, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m), training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    151\u001b[0m )\n\u001b[1;32m    152\u001b[0m disc_real_paint1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdhead1(\n\u001b[1;32m    153\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpaint_disc(aug_real_paint, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m), training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    154\u001b[0m )\n\u001b[1;32m    155\u001b[0m disc_fake_paint2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdhead2(\n\u001b[1;32m    156\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpaint_disc(aug_fake_paint, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m), training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    157\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/laurendurivault/Documents/GitHub/laurendudu/gans-and-monet/tulip/lib/python3.8/site-packages/keras/engine/training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/laurendurivault/Documents/GitHub/laurendudu/gans-and-monet/tulip/lib/python3.8/site-packages/keras/engine/training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/laurendurivault/Documents/GitHub/laurendudu/gans-and-monet/tulip/lib/python3.8/site-packages/keras/engine/training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/laurendurivault/Documents/GitHub/laurendudu/gans-and-monet/utils/dualdiscriminator.py\", line 149, in train_step\n        disc_fake_paint1 = self.dhead1(\n    File \"/Users/laurendurivault/Documents/GitHub/laurendudu/gans-and-monet/tulip/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/laurendurivault/Documents/GitHub/laurendudu/gans-and-monet/tulip/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model_4\" is incompatible with the layer: expected shape=(None, 30, 30, 512), found shape=(32, 33, 33, 512)\n"
     ]
    }
   ],
   "source": [
    "cycle_gan_model.fit(final_dataset, steps_per_epoch=1407, epochs=23, callbacks=[callbacks])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualising the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_iter = iter(photo_ds)\n",
    "for n_sample in range(8):\n",
    "        example_sample = next(ds_iter)\n",
    "        generated_sample = paint_generator(example_sample)\n",
    "        \n",
    "        f = plt.figure(figsize=(32, 32))\n",
    "        \n",
    "        plt.subplot(121)\n",
    "        plt.title('Input image')\n",
    "        plt.imshow(example_sample[0] * 0.5 + 0.5)\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(122)\n",
    "        plt.title('Generated image')\n",
    "        plt.imshow(generated_sample[0] * 0.5 + 0.5)\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_iter = iter(paint_ds)\n",
    "for n_sample in range(10):\n",
    "\n",
    "        example_sample = next(ds_iter)\n",
    "        generated_sample = photo_generator(example_sample)\n",
    "        \n",
    "        f = plt.figure(figsize=(24, 24))\n",
    "        \n",
    "        plt.subplot(121)\n",
    "        plt.title('Input image')\n",
    "        plt.imshow(example_sample[0] * 0.5 + 0.5)\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(122)\n",
    "        plt.title('Generated image')\n",
    "        plt.imshow(generated_sample[0] * 0.5 + 0.5)\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "! mkdir ../images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "i = 1\n",
    "for img in fast_photo_ds:\n",
    "    prediction = monet_generator(img, training=False).numpy()\n",
    "    prediction = (prediction * 127.5 + 127.5).astype(np.uint8)\n",
    "    for pred in prediction:\n",
    "        im = PIL.Image.fromarray(pred)\n",
    "        im.save(\"output/images/\" + str(i) + \".jpg\")\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.make_archive(\"output/output_cyclegan\", 'zip', \"output/images\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = 'images/dualD/'\n",
    "paint_generator.save(SAVE_PATH + f'G_{PAINTER}.h5')\n",
    "photo_generator.save(SAVE_PATH + 'G_photo.h5')\n",
    "paint_discriminator.save(SAVE_PATH + f'D_{PAINTER}.h5')\n",
    "photo_discriminator.save(SAVE_PATH + 'D_photo.h5')\n",
    "d_head_bce.save(SAVE_PATH + 'D_head_bce.h5')\n",
    "d_head_hinge_loss.save(SAVE_PATH + 'D_head_hinge_loss.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tulip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fe1432100fa846dd20953a7d0c263945e5c9df579f052187ee666d4bb0f5c425"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
